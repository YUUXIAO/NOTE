## HTTP

> HTTP是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范

####  特点

1. **灵活可扩展**：一个是语法上只规定了基本格式，空格分隔单词，换行分隔字段等；一个是传输形式的多样性：可以传输文本、图片、视频等任意数据；
2. **请求-应答模式**：就是一方发送消息，另一方要接收消息，或者做出相应等；
3. **可靠传输**：HTTP是基于 TCP / IP ，因此把这一特性继承了下来；
4. **无状态**

#### 缺点

1. **无状态**：有时候需要保存用户信息，比如购物系统，需要保留下顾客信息等等，另外一方面，有时候，无状态也会减少网络开销，比如类似直播行业这样子等；
2. **明文传输**：协议里的报文(主要指的是头部)不使用二进制数据，而是文本形式。这让HTTP的报文信息暴露给了外界，给攻击者带来了便利；
3. **队头阻塞**：由 于HTTP 基本的“请求 - 应答”模型，当http开启长连接时，共用一个TCP连接，当某个请求时间过长时，其他的请求只能处于阻塞状态；
   - **http1.0的队首阻塞**：对于同一个tcp连接，所有的http1.0请求放入队列中，只有前一个请求的响应收到了，然后才能发送下一个请求；http1.0的队首组塞发生在客户端。
   -  **http1.1的队首阻塞**：对于同一个tcp连接，http1.1允许一次发送多个http1.1请求，也就是说，不必等前一个响应收到，就可以发送下一个请求，这样就解决了http1.0的客户端的队首阻塞。但http1.1规定，服务器端的响应的发送要根据请求被接收的顺序排队，也就是说，先接收到的请求的响应也要先发送。这样如果最先收到的请求的处理时间长的话，响应生成也慢，就会阻塞已经生成了的响应的发送；http1.1的队首阻塞发生在服务器端。
   - **http2解决队首阻塞**：http2无论在客户端还是在服务器端都不需要排队，在同一个tcp连接上，有多个stream，由各个stream发送和接收http请求，各个steam相互独立，互不阻塞；只要tcp没有人在用那么就可以发送已经生成的requst或者reponse的数据，在两端都不用等，从而彻底解决了http协议层面的队首阻塞问题。

### HTTP 0.9

> 1991年,原型版本，功能简陋，只有一个命令GET,只支持纯文本内容，该版本已过时。

### http 1.0

> Http 1.0 的致命缺点,就是无法复用 TCP 连接和并行发送请求；

- 任何格式的内容都可以发送，这使得互联网不仅可以传输文字，还能传输图像、视频、二进制等文件；
- 除了GET命令，还引入了 POST 命令和 HEAD 命令；
- http请求和回应的格式改变，除了数据部分，每次通信都必须包括头信息（HTTP header），用来描述一些元数据；
- 只使用 header 中的 If-Modified-Since 和 Expires 作为缓存失效的标准；
- 不支持断点续传，也就是说，每次都会传送全部的页面和数据；
- 通常每台计算机只能绑定一个 IP，所以请求消息中的 URL 并没有传递主机名;

**问题：**

1. 是一种无状态、无连接的应用层协议
   - 无连接：HTTP1.0规定浏览器和服务器保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器处理完成后立即断开TCP连接；这种特性导致最大的性能缺陷就是无法复用连接：每次发送请求的时候，都需要进行一次TCP的连接，而TCP的连接释放过程又是比较费事的。这种无连接的特性会使得网络的利用率非常低。
   - 无状态：服务器不跟踪每个客户端也不记录过去的请求，这种无状态性可以借助cookie/session机制来做身份认证和状态记录；
2. 队头阻塞：由于HTTP1.0规定下一个请求必须在前一个请求响应到达之前才能发送。假设前一个请求响应一直不到达，那么下一个请求就不发送，同样的后面的请求也给阻塞了。
3. 本地时间被修改导致响应头expires的缓存机制失效的问题；

### Http 1.1

- 引入了持久连接：即TCP连接默认不关闭，进而可以复用这个通道，不用声明Connection: keep-alive，长连接的连接时长可以通过请求头中的 keep-alive 来设置；
- 引入了管道机制：即在同一个TCP连接里，客户端可以同时发送多个 请求，进一步改进了HTTP协议的效率；
- 新增加了 E-tag，If-Unmodified-Since, If-Match, If-None-Match 等缓存控制标头来控制缓存失效；
- 支持断点续传，通过使用请求头中的 Range 来实现；
- 使用了虚拟网络，在一台物理服务器上可以存在多个虚拟主机，它们共享一个IP地址；
- 新增方法：PUT、 PATCH、 OPTIONS、 DELETE；

**问题：**

1. 通信使用明文 ， 内容可能会被窃听；
2. 无状态连接：客户端和服务器端都无法验证对方的身份，无法保证数据的安全性；
3. 队头阻塞：默认允许复用TCP连接，这样不必等前一个响应收到，就可以发送下一个请求，就解决了http1.0的客户端的队首阻塞。但是在同一个TCP连接里，所有数据通信是按次序进行的，先接收到的请求的响应也要先发送；这样如果最先收到的请求的处理时间长的话，响应生成也慢，就会阻塞已经生成了的响应的发送；
4. 支持Keep-alive，用来弥补创建多次连接产生的延迟，但是同样会给服务器带来压力，并且的话，对于单文件被不断请求的服务，Keep-alive会极大影响性能，因为它在文件被请求之后还保持了不必要的连接很长时间。
5. 臃肿的消息首部：HTTP/1.1能压缩请求内容,但是消息首部不能压缩;在现今请求中,消息首部占请求绝大部分(甚至是全部)也较为常见.

### Http 2.0

> HTTP2.0的主要优点有采用二进制帧封装，传输变成多路复用，流量控制算法优化（没滑动窗口协议），服务器端推送，首部压缩，优先级等特点；

#### 头部压缩

HTTP 1.1版本会出现 「User-Agent、Cookie、Accept、Server、Range」 等字段可能会占用几百甚至几千字节，而 Body 却经常只有几十字节，所以导致头部偏重。

HTTP 2.0 使用 HPACK 算法进行压缩：

![img](https://user-images.githubusercontent.com/34484322/89356545-a3fd4100-d6f0-11ea-8e0a-8870d832e96e.png)

从上面看，我们可以看到类似于索引表，每个索引表对应一个值，比如索引为2对应头部中的method头部信息，这样子的话，在传输的时候，不在是传输对应的头部信息了，而是传递索引，对于之前出现过的头部信息，只需要把「索引」比如1，2，...)传给对方即可，对方拿到索引查表就行了；这种「传索引」的方式，可以说让请求头字段得到极大程度的精简和复用。

其次是对于整数和字符串进行「哈夫曼编码」，哈夫曼编码的原理就是先将所有出现的字符建立一张索引表，然后让出现次数多的字符对应的索引尽可能短，传输的时候也是传输这样的「索引序列」，可以达到非常高的压缩率。

#### 多路复用

> 复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，这样子解决了队头阻塞的问题；

相比较http/1.1的优势：

1. 同域名下所有通信都在单个连接上完成；
2. 单个连接可以承载任意数量的双向数据流；
3. 数据流以消息的形式发送，而消息又由一个或多个帧组成，多个帧之间可以乱序发送，因为根据帧首部的流标识可以重新组装，也就是 Stream ID，流标识符，有了它，接收方就能从乱序的二进制帧中选择ID相同的帧，按照顺序组装成请求/响应报文；

#### 服务器推送

> 浏览器发送一个请求，服务器主动向浏览器推送与这个请求相关的资源，这样浏览器就不用发起后续请求

相比较http/1.1的优势：

1. 推送资源可以由不同页面共享；
2. 服务器可以按照优先级推送资源；
3. 客户端可以缓存推送的资源；
4. 客户端可以拒收推送过来的资源；

#### 二进制分帧

之前是明文传输，不方便计算机解析，对于回车换行符来说到底是内容还是分隔符，都需要内部状态机去识别，这样子效率低，HTTP/2采用二进制格式，全部传输01串，便于机器解码；

这样子一个报文格式就被拆分为一个个二进制帧，用「Headers帧」存放头部字段，「Data帧」存放请求体数据。这样子的话，就是一堆乱序的二进制帧，它们不存在先后关系，因此不需要排队等待，解决了HTTP队头阻塞问题。

在客户端与服务器之间，双方都可以互相发送二进制帧，这样子「双向传输的序列」，称为流，所以HTTP/2中以流来表示一个TCP连接上进行多个数据帧的通信，这就是多路复用概念。

那乱序的二进制帧，是如何组装成对于的报文呢？

- 乱序指的是不同ID的Stream是乱序的，对于同一个Stream ID的帧是按顺序传输的。
- 接收方收到二进制帧后，将相同的Stream ID组装成完整的请求报文和响应报文。
- 二进制帧中有一些字段，控制着优先级和流量控制等功能，这样子的话，就可以设置数据帧的优先级，让服务器处理重要资源，优化用户体验。

### https

> HTTP+ 加密 + 认证 + 完整性保护 =HTTPS
>
> 我们把添加了加密及认证机制的 HTTP 称为 HTTPS；

- 如果在 HTTP 协议通信过程中使用未经加密的明文，比如在 Web 页面中输入信用卡号，如果这条通信线路遭到窃听，那么信用卡号就暴露了；
- 对于 HTTP 来说，服务器也好，客户端也好，都是没有办法确认通信方的。

因为很有可能并不是和原本预想的通信方在实际通信。并且还需要考虑到接收到的报文在通信途中已经遭到篡改这一可能性，为了统一解决这些问题，需要在 HTTP 上再加入加密处理和认证等机制。

#### HTTPS 是身披 SSL 外壳的 HTTP

HTTPS 并非是应用层的一种新协议。只是 HTTP 通信接口部分用 SSL（SecureSocket Layer）和 TLS（Transport Layer Security）协议代替而已。

通常，HTTP 直接和 TCP 通信

- 当使用 SSL 时，则演变成先和 SSL 通信，再由 SSL和 TCP 通信了。
- 在采用 SSL 后，HTTP 就拥有了 HTTPS 的加密、证书和完整性保护这些功能。
- SSL 是独立于 HTTP 的协议，所以不光是 HTTP 协议，其他运行在应用层的 SMTP和 Telnet 等协议均可配合 SSL 协议使用。可以说 SSL 是当今世界上应用最为广泛的网络安全术。

#### 相互交换密钥的公开密钥加密技术 -----对称加密

> 加密和解密都会用到密钥。没有密钥就无法对密码解密，反过来说，任何人只要持有密钥就能解密了。如果密钥被攻击者获得，那加密也就失去了意义。

- SSL 采用一种叫做公开密钥加密（Public-key cryptography）的加密处理方式。
- 近代的加密方法中加密算法是公开的，而密钥却是保密的。通过这种方式得以保持加密方法的安全性。

#### HTTPS 采用混合加密机制

- HTTPS 采用共享密钥加密和公开密钥加密两者并用的混合加密机制。
- 但是公开密钥加密与共享密钥加密相比，其处理速度要慢。所以应充分利用两者各自的优势，将多种方法组合起来用于通信。在交换密钥环节使用公开密钥加密方式，之后的建立通信交换报文阶段则使用共享密钥加密方式。

#### 存在的问题

HTTPS 也存在一些问题，那就是当使用 SSL 时，它的处理速度会变慢。

SSL 的慢分两种：一种是指通信慢；另一种是指由于大量消耗 CPU 及内存等资源，导致处理速度变慢。

- 和使用 HTTP 相比，网络负载可能会变慢 2 到 100 倍。除去和 TCP 连接、发送 HTTP 请求 和响应以外，还必须进行 SSL 通信，因此整体上处理通信量不可避免会增加。
- 另一点是 SSL 必须进行加密处理。在服务器和客户端都需要进行加密和解密的运算处理。因此从结果上讲，比起 HTTP 会更多地消耗服务器和客户端的硬件资源，导致负载增强。

针对速度变慢这一问题，并没有根本性的解决方案，可以使用 SSL 加速器这种（专用服务器）硬件来改善该问题。该硬件为 SSL 通信专用硬件，相对软件来讲，能够提高数倍 SSL 的计算速度。仅在 SSL 处理时发挥 SSL加速器的功效，以分担负载。

#### 为什么不一直使用 HTTPS

- 其中一个原因是，因为与纯文本通信相比，加密通信会消耗更多的 CPU 及内存资源。如果每次通信都加密，会消耗相当多的资源，平摊到一台计算机上时，能够处理的请求数量必定也会随之减少；因此，如果是非敏感信息则使用 HTTP 通信，只有在包含个人信息等敏感数据时，才利用 HTTPS 加密通信，以节约资源。特别是每当那些访问量较多的 Web 网站在进行加密处理时，它们所承担着的负载不容小觑。在进行加密处理时，并非对所有内容都进行加密处理，而是仅在那些需要信息隐藏时才会加密。
- 除此之外，想要节约购买证书的开销也是原因之一：进行 HTTPS 通信，证书是必不可少的。而使用的证书必须向认证机构（CA）购买。证书价格可能会根据不同的认证机构略有不同。那些购买证书并不合算的服务以及一些个人网站，可能只会选择采用HTTP 的通信方式。

## webSocket

> 传统的协议无法服务端主动 push 数据，于是有了这些骚操作：
>
> - 轮询，在一个定时器中不停向服务端发送请求；
> - 长轮询，发送请求给服务端，直到服务端觉得可以返回数据了再返回响应，否则这个请求一直挂起；

为了解决实时通讯，数据同步的问题，出现了 webSocket：

1. webSockets 的目标是在一个单独的持久连接上提供全双工、双向通信。在Javascript创建了Web Socket之后，会有一个HTTP请求发送到浏览器以发起连接。在取得服务器响应后，建立的连接会将HTTP升级从HTTP协议交换为WebSocket协议。
2. webSocket 原理： 在TCP连接第一次握手的时候，升级为ws协议。后面的数据交互都复用这个TCP通道。

```javascript
const ws = new WebSocket('ws://localhost:8080');
ws.onopen = function () {
    ws.send('123')
    console.log('open')
}
ws.onmessage = function () {
    console.log('onmessage')
}
ws.onerror = function () {
    console.log('onerror')
}
ws.onclose = function () {
    console.log('onclose')
}
```

## HTTP 状态码

> RFC 规定 HTTP 的状态码为「三位数」，第一个数字定义了响应的类别，被分为五类:

- **「1xx」**: 代表请求已被接受，需要继续处理。
- **「2xx」**: 表示成功状态。
- **「3xx」**: 重定向状态。
- **「4xx」**: 客户端错误。
- **「5xx」**: 服务器端错误。

### 「1xx」 信息类

> 接受的请求正在处理，信息类状态码。

### 「2xx」 成功

- 200 OK ：表示从客户端发来的请求在服务器端被正确请求；
- 204 No content：表示请求成功，但没有资源可返回；
- 206 Partial Content：该状态码表示客户端进行了范围请求，而服务器成功执行了这部分的 GET 请求响应报文中包含由 「Content-Range」 指定范围的实体内容；

### 「3xx」 重定向

- 301：永久性重定向，表示目标资源被永久的移动到了一个新的 URI，任何未来对这个资源的引用都应该使用新的 URI；

- 302 found：临时性重定向表示目标资源临时移动到了另一个 URI 上；由于重定向是临时发生的，所以客户端在之后的请求中还应该使用原本的 URI。

  ```
  由于历史原因，用户代理可能会在重定向后的请求中把 POST 方法改为 GET 方法。
  ```

- 303 see other：表示服务器要将浏览器重定向到另一个资源，这个资源的 URI 会被写在响应 Header 的 Location 字段。

  从语义上讲，重定向到的资源并不是你所请求的资源，而是对你所请求资源的一些描述。

  303 常用于将 POST 请求重定向到 GET 请求，比如你上传了一份个人信息，服务器发回一个 303 响应，将你导向一个“上传成功”页面。

  ```
  不管原请求是什么方法，重定向请求的方法都是 GET
  ```

- 304 not modified：当协商缓存命中时会返回这个状态码；

- 307 temporary redirect：定义实际上和 302 是一致的，唯一的区别在于，307 状态码不允许浏览器将原本为 POST 的请求重定向到 GET 请求上。

```
302 允许各种各样的重定向，一般情况下都会实现为到 GET 的重定向，但是不能确保 POST 会重定向为 POST；而 303 只允许任意请求到 GET 的重定向；307 和 302 一样，除了不允许 POST 到 GET 的重定向。
```

### 「4xx」 客户端错误

- 400 bad request，请求报文存在语法错误；

- 401 unauthorized，表示发送的请求需要有通过 HTTP 认证的认证信息；

- 403 forbidden，表示对请求资源的访问被服务器拒绝；

- 404 not found，表示在服务器上没有找到请求的资源；

- 405 Method Not Allowed，服务器禁止使用该方法，客户端可以通过options方法来查看服务器允许的访问方法

  ```javascript
  Access-Control-Allow-Methods →GET,HEAD,PUT,PATCH,POST,DELETE
  ```

### 「5xx」 服务器错误

- 500 internal sever error，表示服务器端在执行请求时发生了错误;
- 502 Bad Gateway，服务器自身是正常的，访问的时候出了问题，具体啥错误我们不知道;
- 503 service unavailable，表明服务器暂时处于超负载或正在停机维护，无法处理请求;

## DNS

> DNS 协议提供的是一种主机名到 IP 地址的转换服务，就是我们常说的域名系统。是应用层协议，通常该协议运行在UDP协议之上，使用的是53端口号

### 使用 UDP 协议作为传输层协议

> DNS 使用 UDP 协议作为传输层协议主要是为了避免使用 TCP 协议时造成的连接时延；

- 为了得到一个域名的 IP 地址，往往会向多个域名服务器查询，如果使用 TCP 协议，那么每次请求都会存在连接时延，这样使 DNS 服务变得很慢；
- 大多数的地址查询请求，都是浏览器请求页面时发出的，这样网页的等待时间过长；

### 递归查询和迭代查询

1. 递归查询：指的是查询请求发出后，域名服务器代为向下一级域名服务器发出请求，最后向用户返回查询的最终结果。使用递归 查询，用户只需要发出一次查询请求；
2. 迭代查询：指的是查询请求后，域名服务器返回单次查询的结果。下一级的查询由用户自己请求。使用迭代查询，用户需要发出 多次的查询请求；

所以一般而言，「本地服务器查询是递归查询」，而「本地 DNS 服务器向其他域名服务器请求的过程是迭代查询的过程」。

查询过程：本地查询是递归查询，依次通过浏览器缓存 ==》 本地hosts文件 ==》 本地DNS解析器 ==》本地DNS服务器 ==》 其他域名服务器请求； 接下来的过程就是迭代过程。

### DNS缓存

在一个请求中，当某个DNS服务器收到一个DNS回答后，它能够回答中的信息缓存在本地存储器中，返回的资源记录中的 TTL 代表了该条记录的缓存的时间。

### DNS实现负载平衡

> DNS 是可以用于在冗余的服务器上实现负载平衡，因为一般的大型网站使用多台服务器提供服务，因此一个域名可能会对应 多个服务器地址；

例如：

- 当用户发起网站域名的 DNS 请求的时候，DNS 服务器返回这个域名所对应的服务器 IP 地址的集合；
- 在每个回答中，会循环这些 IP 地址的顺序，用户一般会选择排在前面的地址发送请求；
- 以此将用户的请求均衡的分配到各个不同的服务器上，这样来实现负载均衡；

## TCP

> TCP是因特网中的传输层协议，使用三次握手协议建立连接。当主动方发出SYN连接请求后，等待对方回答；
>
> TCP 是一个可靠传输的协议，那它是如何保证可靠的呢？
>
> ```
> TCP 是通过序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输的。
> ```

### 重传机制

> TCP 实现可靠传输的方式之一：是通过序列号与确认应答。

在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。

![img](https://user-gold-cdn.xitu.io/2020/7/25/17384f114569c301?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

但在错综复杂的网络，并不一定能如上图那么顺利能正常的数据传输，万一数据在传输过程中丢失了呢？所以 TCP 针对数据包丢失的情况，会用重传机制解决：

#### 超时重传

> 重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 ACK 确认应答报文，就会重发该数据。

- 每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。
- 超时触发重传存在的问题是，超时周期可能相对较长。

于是就可以用「快速重传」机制来解决超时重发的时间等待。

#### 快速重传

> 快速重传（Fast Retransmit）机制，它不以时间为驱动，而是以数据驱动重传。

![img](https://user-gold-cdn.xitu.io/2020/7/25/17384f116656218a?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)



在上图，发送方发出了 1，2，3，4，5 份数据：

- 第一份 Seq1 先送到了，于是就 Ack 回 2；
- 结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2；
- 后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到；
- 发送端收到了三个 Ack = 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。
- 最后，接收到收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。

所以，快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。

快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是重传的时候，是重传之前的一个，还是重传所有的问题。

比如对于上面的例子，是重传 Seq2 呢？还是重传 Seq2、Seq3、Seq4、Seq5 呢？因为发送端并不清楚这连续的三个 Ack 2 是谁传回来的。

为了解决不知道该重传哪些 TCP 报文，于是就有 SACK 方法。

#### SACK

> SACK（ Selective Acknowledgment 选择性确认）；
>
> 这种方式需要在 TCP 头部「选项」字段里加一个 SACK 的东西，它可以将缓存的地图发送给发送方，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据；

![img](https://user-gold-cdn.xitu.io/2020/7/25/17384f117128506f?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)



#### Duplicate  SACK

> Duplicate SACK 又称 D-SACK，主要使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。

![img](https://user-gold-cdn.xitu.io/2020/7/25/17384f11748d020f?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

ACK 丢包

- 「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）。
- 于是「接收方」发现数据是重复收到的，于是回了一个 SACK = 3000~3500，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 D-SACK。
- 这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。

![img](https://user-gold-cdn.xitu.io/2020/7/25/17384f118232614c?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

网络延时

- 数据包（1000~1499） 被网络延迟了，导致「发送方」没有收到 Ack 1500 的确认报文。
- 而后面报文到达的三个相同的 ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」；
- 所以「接收方」回了一个 SACK=1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。
- 这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。

D-SACK 的好处：

1. 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;
2. 可以知道是不是「发送方」的数据包被网络延迟了;
3. 可以知道网络中是不是把「发送方」的数据包给复制了;

### 滑动窗口协议

> 滑动窗口通俗来讲就是一种流量控制技术；
>
> 本质上是描述接收方的TCP数据报缓冲区大小的数据，发送方根据这个数据来计算自己最多能发送多长的数据，如果发送方收到接收方的窗口大小为0的TCP数据报，那么发送方将停止发送数据，等到接收方发送窗口大小不为0的数据报的到来；
>
> 主要为了解决在网络传输数据的过程中，发送方和接收方传输数据速率不一致的问题，从而保证数据传输的可靠性，达到流量控制的效果。

TCP 是每发送一个数据，都进行一次确认应答。当上一个数据包收到了应答， 再发送下一个；这种传输方式有一个缺点：数据包的往返时间越长，通信的效率就越低，吞吐量非常的低。

##### 窗口

> 窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值；
>
> 窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。

假设窗口大小为 3 个 TCP 段，那么发送方就可以「连续发送」 3 个 TCP 段，并且中途若有 ACK 丢失，可以通过「下一个确认应答进行确认」。如下图：

![img](https://user-gold-cdn.xitu.io/2020/7/25/17384f118863234b?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)



**窗口大小由哪一方决定？**

- 通常窗口的大小是由接收方的决定的。
- TCP 头里有一个字段叫 Window，也就是窗口大小。
- 这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。
- 发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。

**发送方的滑动窗口**

![img](https://user-gold-cdn.xitu.io/2020/7/25/17384f11a6572ab5?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

\#1 是已发送并收到 ACK 确认的数据：1~31 字节

\#2 是已发送但未收到 ACK 确认的数据：32~45 字节

\#3 是未发送但总大小在接收方处理范围内（接收方还有空间）：46~51 字节

\#4 是未发送但总大小超过接收方处理范围（接收方没有空间）：52 字节以后

当发送方把数据「全部」都一下发送出去后，可用窗口的大小就为 0 了，表明可用窗口耗尽，在没收到 ACK 确认之前是无法继续发送数据了。

![img](https://user-gold-cdn.xitu.io/2020/7/25/17384f119ca2a493?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

当收到之前发送的数据 32~36 字节的 ACK 确认应答后，如果发送窗口的大小没有变化，则滑动窗口往右边移动 5 个字节，因为有 5 个字节的数据被应答确认，接下来 52~56 字节又变成了可用窗口，那么后续也就可以发送 52~56这 5 个字节的数据了。

![img](https://user-gold-cdn.xitu.io/2020/7/25/17384f11a9324c17?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

**程序是如何表示发送方的四个部分的呢？**

TCP 滑动窗口方案使用三个指针来跟踪在四个传输类别中的每一个类别中的字节。其中两个指针是绝对指针（指特定的序列号），一个是相对指针（需要做偏移）。

![img](https://user-gold-cdn.xitu.io/2020/7/25/17384f11ace81178?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

SND.WND、SND.UN、SND.NXT

- SND.WND：表示发送窗口的大小；
- SND.UNA：是一个绝对指针，它指向的是已发送但未收到确认的第一个字节的序列号。
- SND.NXT：也是一个绝对指针，它指向未发送但可发送范围的第一个字节的序列号。
- 指向 #4 的第一个字节是个相对指针，它需要 SND.UNA 指针加上 SND.WND 大小的偏移量，就可以指向 #4 的第一个字节了。

**接收方的滑动窗口**

- \#1 + #2 是已成功接收并确认的数据（等待应用进程读取）；
- \#3 是未收到数据但可以接收的数据；
- \#4 未收到数据并不可以接收的数据；

![img](https://user-gold-cdn.xitu.io/2020/7/25/17384f11b680af2c?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)



其中三个接收部分，使用两个指针进行划分:

- RCV.WND：表示接收窗口的大小，它会通告给发送方。
- RCV.NXT：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号。
- 指向 #4 的第一个字节是个相对指针，它需要 RCV.NXT 指针加上RCV.WND 大小的偏移量，就可以指向 #4 的第一个字节了。

**接收窗口和发送窗口的大小是相等的吗？**

并不是完全相等，接收窗口的大小是约等于发送窗口的大小的。

因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。

### 流量控制

发送方不能无脑的发数据给接收方，要考虑接收方处理能力；如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。

为了解决这种现象发生，TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。

#### 死锁状态

> 当接收端向发送端发送零窗口报文段后不久，接收端的接收缓存又有了一些存储空间，于是接收端向发送端发送了Windows size = 2的报文段，然而这个报文段在传输过程中丢失了。发送端一直等待收到接收端发送的非零窗口的通知，而接收端一直等待发送端发送数据，这样就死锁了。

解决方法：

```
TCP为每个连接设有一个持续计时器。只要TCP连接的一方收到对方的零窗口通知，就启动持续计时器，若持续计时器设置的时间到期，就发送一个零窗口探测报文段（仅携带1字节的数据），而对方就在确认这个探测报文段时给出了现在的窗口值。
```

#### Negle算法

Negle算法主要为了解决TCP的传输效率问题。Negle算法规定：

若要把发送的数据逐个字节缓存起来，则发送方需要把第一个字节发送出去，然后缓存后面的字节，在收到接收方第一个字节的确认，再将现有缓存中所有字节组成一个报文段发送出去，继续缓存后续数据。只有在收到前一个报文的确认之后发送后面的数据。这是为了减少所用带宽。当发送数据到达TCP发送窗口的一半或已达到报文段的最大长度也会立即发送报文段，而不是等待接收方确认。这是为了提高网络吞吐量。

#### 糊涂窗口综合征

TCP接收方的缓存已满，若上层一次从缓存中读取一个字节，这样接收方就可以继续接纳一个字节的窗口，然后向发送方发送确认，把窗口设为1个字节（上文所讲，IP数据报为41字节长）。如果这样持续下去，那么网络效率非常低。

所以有效的解决方法，就是让接收方等待一定时间，让缓存空间能够接纳一个最长的报文段，或者等待接收缓存已有一半的空闲空间，再发出确认报文和通知当前窗口大小。